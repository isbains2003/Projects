{"cells":[{"metadata":{},"cell_type":"markdown","source":"**[Introduction to Machine Learning Home Page](https://www.kaggle.com/learn/intro-to-machine-learning)**\n\n---\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Introduction\nMachine learning competitions are a great way to improve your data science skills and measure your progress. \n\nIn this exercise, you will create and submit predictions for a Kaggle competition. You can then improve your model (e.g. by adding features) to improve and see how you stack up to others taking this micro-course.\n\nThe steps in this notebook are:\n1. Build a Random Forest model with all of your data (**X** and **y**)\n2. Read in the \"test\" data, which doesn't include values for the target.  Predict home values in the test data with your Random Forest model.\n3. Submit those predictions to the competition and see your score.\n4. Optionally, come back to see if you can improve your model by adding features or changing your model. Then you can resubmit to see how that stacks up on the competition leaderboard.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Recap\nHere's the code you've written so far. Start by running it again.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up code checking\nimport os\nif not os.path.exists(\"../input/train.csv\"):\n    os.symlink(\"../input/home-data-for-ml-course/train.csv\", \"../input/train.csv\")  \n    os.symlink(\"../input/home-data-for-ml-course/test.csv\", \"../input/test.csv\") \nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.machine_learning.ex7 import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Code you have previously used to load data\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.tree import DecisionTreeRegressor\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import preprocessing\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\nfrom xgboost import XGBRegressor\nfrom sklearn.feature_selection import SelectKBest, f_classif\nfrom sklearn.decomposition import PCA\nfrom scipy import stats\nfrom scipy.stats import norm, skew","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#treating outliers\n\ndef upper_cap (data, col):\n    return np.mean (data [col]) + np.std (data [col])*2.1\ndef lower_cap (data, col):\n    return np.mean (data [col]) - np.std (data [col])*2.5\n\ndef capping (data, list):\n    for col in list:\n        data.loc[(data [col] > upper_cap (data, col)),col] = upper_cap (data, col)\n        data.loc[(data[col] < lower_cap (data, col)),col] = lower_cap (data, col)\n    return data [list]\n\n#removing elemenents from a list\ndef element_remove (list, list1):\n    for element in list1:\n        if element in list:\n            list.remove(element)\n    return list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Path of the file to read. We changed the directory structure to simplify submitting to a competition\niowa_file_path = '../input/train.csv'\n# path to file you will use for predictions\ntest_data_path = '../input/test.csv'\n\n# read training data file using pandas\nhome_data = pd.read_csv(iowa_file_path)\n# read test data file using pandas\ntest_data = pd.read_csv (test_data_path)\n\nsns.set_style ('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(home_data ['GrLivArea'], home_data ['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"home_data = home_data.drop(home_data[(home_data['GrLivArea']>4000) & (home_data['SalePrice']<300000)].index)\n\n#Check the graphic\nfig, ax = plt.subplots()\nax.scatter(home_data ['GrLivArea'], home_data ['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"home_data ['SalePrice'].describe ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = home_data ['SalePrice']\ntrain_ID = home_data ['Id']\ntest_ID = test_data ['Id']\n\nhome_data.drop ('SalePrice', axis = 1, inplace = True)\nhome_data.drop ('Id', axis = 1, inplace = True)\ntest_data.drop ('Id', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.log1p (Y)\nsns.distplot (y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.concat ([home_data, test_data])\n\nprint ('data shape', data.shape)\nprint ('Dtypes in the home_data are : {}'.format (data.dtypes.unique ()))\n\ncategorical_cols = list (data.dtypes [(data.dtypes == object)|(data.dtypes == 'O')].index)\nnumerical_cols = list (data.dtypes [(data.dtypes == 'int64')|(data.dtypes == 'float64')].index)\n\nprint ('categorical_cols', len (categorical_cols))\nprint ('numerical_cols', len (numerical_cols))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Correcting Dtypes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data ['MSSubClass'] = data ['MSSubClass'].astype ('object')\ndata ['OverallQual'] = data ['OverallQual'].astype ('object')\ndata ['Fireplaces'] = data ['Fireplaces'].astype ('object')\ndata ['OverallCond'] = data ['OverallCond'].astype ('object')\ndata ['GarageCars'] = data ['GarageCars'].astype ('object')\ndata [['BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd']] = data [['BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd']].astype ('object')\ndata [['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath']] = data [['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath']].astype ('object')\n\n\ncategorical_cols = list (data.dtypes [(data.dtypes == object)|(data.dtypes == 'O')].index)\n\nnumerical_cols = list (data.dtypes [(data.dtypes == 'int64')|(data.dtypes == 'float64')].index)\n\nprint ('categorical_cols', len (categorical_cols))\nprint ('\\n')\nprint ('numerical_cols', len (numerical_cols))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Categorical_cols : Number of levels per column / levels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"dict = {}\nfor cols in categorical_cols:\n    \n    k = data [cols].nunique ()\n    n = cols\n    dict.update ({n:k})\ncat_cols_nlevels = pd.DataFrame (dict, index = range (0, len(categorical_cols))).transpose ()[0].sort_values ()\ncat_cols_nlevels.plot.barh (figsize = (7,10))\nplt.title ('Categorical_cols_nlevels')\nplt.yticks (fontsize = 7)\nplt.show ()\n\ndict1 = {}\nfor cols in categorical_cols:\n    k1 = str (data [cols].unique ())\n    n1 = cols\n    dict1.update ({n1:k1})\ncat_cols_levels = pd.DataFrame (dict1, index = range (0, len (categorical_cols))).transpose ()[0]\nprint (cat_cols_levels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Categorical_cols : Missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure (figsize = (8,10))\ncat_nulls = data [categorical_cols].isnull ().sum ()\ncat_nulls_gr0 = cat_nulls [cat_nulls > 0].sort_values ()\ncat_nulls_gr0.plot.barh (title = 'Categorical_cols_MissingValues')\nplt.show ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (cat_nulls_gr0.index, ' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['MSZoning'] = data['MSZoning'].fillna(data['MSZoning'].mode()[0])\ndata['GarageCars'] = data['GarageCars'].fillna(0)\ndata['Exterior1st'] = data['Exterior1st'].fillna(data['Exterior1st'].mode()[0])\ndata['Exterior2nd'] = data['Exterior2nd'].fillna(data['Exterior2nd'].mode()[0])\ndata['Electrical'] = data['Electrical'].fillna(data['Electrical'].mode()[0])\ndata['Functional'] = data['Functional'].fillna(data['Functional'].mode()[0])\ndata['BsmtHalfBath'] = data['BsmtHalfBath'].fillna(0)\ndata['BsmtFullBath'] = data['BsmtFullBath'].fillna(0)\ndata['SaleType'] = data['SaleType'].fillna(data['SaleType'].mode()[0])\ndata [['FireplaceQu', 'Fence', 'Alley', 'MiscFeature', 'PoolQC', 'GarageType', 'GarageQual', 'GarageFinish', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual',\n       'BsmtCond', 'BsmtExposure', 'GarageCond', 'MasVnrType']] = data [['FireplaceQu', 'Fence', 'Alley', 'MiscFeature', 'PoolQC', 'GarageType', 'GarageQual', 'GarageFinish', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual',\n       'BsmtCond', 'BsmtExposure', 'GarageCond', 'MasVnrType']].fillna ('None')\ndata['KitchenQual'] = data['KitchenQual'].fillna(data['KitchenQual'].mode()[0])\ndata['Utilities'] = data['Utilities'].fillna(data['Utilities'].mode()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (data [categorical_cols].isnull ().sum ().sum ())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Numerical_cols : Missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_nulls = data [numerical_cols].isnull ().sum ()\nnum_nulls [num_nulls > 0].sort_values ().plot.barh (title = 'Numerical_cols_MissingValues')\nplt.show ()\n\nprint (num_nulls [num_nulls>0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data ['MasVnrArea'] = data ['MasVnrArea'].fillna (0)\ndata ['GarageYrBlt'] = data ['GarageYrBlt'].fillna (0)\ndata ['LotFrontage'] = data.groupby ('Neighborhood') ['LotFrontage'].transform (lambda x : x.fillna (np.mean (x)))\ndata ['BsmtFinSF1'] = data ['BsmtFinSF1'].fillna (0)\ndata ['BsmtFinSF2'] = data ['BsmtFinSF2'].fillna (0)\ndata ['TotalBsmtSF'] = data ['TotalBsmtSF'].fillna (0)\ndata ['BsmtUnfSF'] = data ['BsmtUnfSF'].fillna (0)\ndata ['GarageArea'] = data ['GarageArea'].fillna (0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (data [numerical_cols].isnull ().sum ().sum ())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# label encoding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols_lb =['OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in categorical_cols_lb:\n    lbl = LabelEncoder() \n    lbl.fit(data[c])\n    data[c] = lbl.transform(data[c])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data [categorical_cols_lb].head (2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# feature engineering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# numerical features\ndata ['TotalSF'] = data  ['TotalBsmtSF'] + data['1stFlrSF'] + data ['2ndFlrSF']\ndata ['YearBuilt_YrSold'] = data ['YrSold'] - data ['YearBuilt']\ndata ['YearRemodAdd_YrSold'] = data ['YrSold'] - data ['YearRemodAdd']\ndata ['GarageYrBlt_YrSold'] = data ['YrSold'] - data ['GarageYrBlt']\n#data ['Other_rooms'] = data ['TotRmsAbvGrd'] - data ['BedroomAbvGr']\nnumerical_cols = element_remove (numerical_cols, ['YrSold', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt']) + ['TotalSF','YearBuilt_YrSold', 'YearRemodAdd_YrSold', 'GarageYrBlt_YrSold' ]\nprint (len (numerical_cols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# categorical features\ndata ['BsmtBath'] = data ['BsmtFullBath'] + data ['BsmtHalfBath']\ndata ['Bath'] = data ['HalfBath'] + data ['FullBath']\n\ncategorical_cols = element_remove (categorical_cols, ['BsmtFullBath','FullBath', 'BsmtHalfBath', 'HalfBath']) + ['Bath', 'BsmtBath']\nprint (len (categorical_cols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data [categorical_cols + numerical_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# checking skewness of numerical cols","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"skewed_cols = data [numerical_cols].apply (lambda x : skew (x)).sort_values (ascending = False)\nskewness = pd.DataFrame ({'skew': skewed_cols})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skewness.tail (10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skewness = skewness [abs (skewness) > 0.75].dropna ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print ('Skewed numerical features {}'.format (skewness.shape [0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.special import boxcox1p\nskewed_features = skewness.index\n\nfor feat in skewed_features:\n    \n    data[feat] = np.log1p(data[feat]+10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"fig = plt.figure (figsize = (20,35))\n\nfor i, col in enumerate (numerical_cols): \n    fig.add_subplot (10,4,i+1) \n    data [col].hist ()\n    plt.xticks (rotation = 90) \n    plt.xlabel (col) \n    plt.tight_layout ()","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Split test - train data now ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data = data [categorical_cols + numerical_cols].iloc [0:1458]\ntesting_data = data [categorical_cols + numerical_cols].iloc [1458:]\ntesting_data ['Id'] = test_ID\nprint (training_data.shape, testing_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(training_data, y, train_size=0.7, test_size=0.3,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train [categorical_cols].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# removing low variance categorical features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"D = data [categorical_cols].describe (exclude = 'number').transpose ()\nD ['portion'] = D['freq']*100/D ['count']\n#print (D.sort_values (by = 'portion', ascending = False))\nlow_variance = D [D.portion > 90].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols = element_remove (categorical_cols, low_variance)\nprint (len (categorical_cols))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Categorical_cols - Univariate EDA","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"fig = plt.figure (figsize = (12,40))\n\nfor i, col in enumerate (categorical_cols):\n    fig.add_subplot (20,4,i+1)\n    sns.countplot (X_train.iloc [0:1460][col])\n    plt.xticks (rotation = 90, fontsize = 5)\nplt.tight_layout ()","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Categorical_cols - Bivariate EDA","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"fig = plt.figure (figsize = (12,40))\n\nfor i, col in enumerate (categorical_cols): \n    fig.add_subplot (20,4,i+1) \n    sns.boxplot (X_train [col],y_train) \n    plt.xticks (rotation = 90, fontsize = 6) \n    plt.tight_layout ()","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\nf=[];p=[]\n\nfor col in categorical_cols:\n    df = pd.DataFrame ({'Y': y_train, 'categorical_col': X_train [col]})\n    model = ols ('Y ~ C(categorical_col)', data=df).fit()\n    anova_table = sm.stats.anova_lm (model, typ=2)\n    f.append(anova_table.iloc[0, 2])\n    p.append(anova_table.iloc[0, 3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"anova = pd.DataFrame({'column': categorical_cols, 'F': f, 'p':p})\nanova = anova.sort_values(by=['F'], ascending=False).reset_index(drop=True)\nplt.figure(figsize=(15,8))\n\nplt.subplot (1,2,1)\nax = sns.barplot(x=anova.F, y=anova.column)\nplt.title('ANOVA F-values on Y', fontsize=14)\n\nplt.subplot (1,2,2)\nax = sns.barplot(x=anova.p, y=anova.column)\nplt.title('ANOVA p-values on Y', fontsize=14)\nplt.tight_layout ()\n\nprint (anova ['F'].describe ())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_cols = list (anova [anova.F > 10]['column'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Numerical_cols : Bivariate EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_data = X_train [numerical_cols]\nnum_data ['SalePrice'] = y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = abs (round (num_data.corr (),3))\nplt.figure (figsize = (5, 5))\ncorr ['SalePrice'].sort_values (ascending = True).plot.barh ()\nplt.title ('Numerical_cols Vs SalePrice Correlation')\nplt.show ()\n\nprint (corr ['SalePrice'].sort_values (ascending = False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_drop = list (corr [abs (corr.SalePrice) <= 0.30]['SalePrice'].sort_values (ascending = False).index)\nnumerical_cols = element_remove (numerical_cols, to_drop)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure (figsize = (9,6))\nsns.heatmap (corr [corr > 0.7], annot = True, cmap = 'Blues')\nplt.show ()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Numerical_cols : After deleting correlated features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical_cols = element_remove (numerical_cols, ['1stFlrSF', 'GrLivArea', '2ndFlrSF', 'TotalBsmtSF'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure (figsize = (20,35))\n\nfor i, col in enumerate (numerical_cols):\n    fig.add_subplot (10,4,i+1)\n    sns.regplot (num_data [col], num_data ['SalePrice'])\n    plt.xticks (rotation = 90)\n    \n    plt.title (col + '  ' + str (round (np.corrcoef (num_data.SalePrice, num_data [col])[0,1],3)))\nplt.tight_layout ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train [numerical_cols] = capping (X_train, numerical_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_features = categorical_cols + numerical_cols\n\nprint (len (total_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing for numerical data\nnumerical_transformer = Pipeline (steps = [('scaler', StandardScaler ())])\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    \n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n     ])\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n            ('num', numerical_transformer, numerical_cols),\n            ('cat', categorical_transformer, categorical_cols)\n    ])\n# Define model\n#model = Lasso (alpha = 10)\n#model = GradientBoostingRegressor ()\n#model = RandomForestRegressor(n_estimators=100, max_depth = 5, random_state=0)\nmodel = XGBRegressor (colsample_bytree=0.4603, gamma=0.05, \n                             learning_rate=0.06, max_depth=5, \n                             min_child_weight=1.7817, n_estimators=5000,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)\n# Bundle preprocessing and modeling code in a pipeline\nclf = Pipeline(steps=[('preprocessor', preprocessor),('model', model)])\n#param = {\"model__n_estimators\":[100,150,200], \"model__learning_rate\":[0.01,0.1,0.05], \"model__max_depth\":[2,3,4,5]}\n#grid = GridSearchCV (clf,param, n_jobs = -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing of training data, fit model \nclf.fit(X_train [total_features], y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Validation function\ndef rmsle_cv(model):\n    n_folds = 5\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grid.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_valid [numerical_cols] = capping (X_valid, numerical_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make validation predictions and calculate mean absolute error\npred_valid = np.exp (clf.predict(X_valid [total_features]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_mae = mean_absolute_error(pred_valid, y_valid)\n\nprint(\"Validation MAE : {:,.0f}\".format(val_mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train [total_features].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_train = np.exp (clf.predict(X_train [total_features]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_mae_t = mean_absolute_error(pred_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Validation MAE_t : {:,.0f}\".format(val_mae_t))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating a Model For the Competition\n\nBuild a Random Forest model and train it on all of **X** and **y**.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Make Predictions\nRead the file of \"test\" data. And apply your model to make predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_data [numerical_cols] = capping (testing_data, numerical_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_data [total_features].columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = testing_data [total_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = np.exp (clf.predict (X))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame({'Id': testing_data.Id,\n                      'SalePrice': test_preds})\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.head ()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before submitting, run a check to make sure your `test_preds` have the right format.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check your answer\nstep_1.check()\nstep_1.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test Your Work\n\nTo test your results, you'll need to join the competition (if you haven't already).  So open a new window by clicking on [this link](https://www.kaggle.com/c/home-data-for-ml-course).  Then click on the **Join Competition** button.\n\n![join competition image](https://i.imgur.com/wLmFtH3.png)\n\nNext, follow the instructions below:\n1. Begin by clicking on the blue **Save Version** button in the top right corner of this window.  This will generate a pop-up window.  \n2. Ensure that the **Save and Run All** option is selected, and then click on the blue **Save** button.\n3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n4. Click on the **Output** tab on the right of the screen.  Then, click on the **Submit to Competition** button to submit your results to the leaderboard.\n\nYou have now successfully submitted to the competition!\n\n5. If you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your model and repeat the process. There's a lot of room to improve your model, and you will climb up the leaderboard as you work.\n\n# Continuing Your Progress\nThere are many ways to improve your model, and **experimenting is a great way to learn at this point.**\n\nThe best way to improve your model is to add features.  Look at the list of columns and think about what might affect home prices.  Some features will cause errors because of issues like missing values or non-numeric data types. \n\nThe **[Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning)** micro-course will teach you how to handle these types of features. You will also learn to use **xgboost**, a technique giving even better accuracy than Random Forest.\n\n\n# Other Micro-Courses\nThe **[Pandas](https://kaggle.com/Learn/Pandas)** micro-course will give you the data manipulation skills to quickly go from conceptual idea to implementation in your data science projects. \n\nYou are also ready for the **[Deep Learning](https://kaggle.com/Learn/Deep-Learning)** micro-course, where you will build models with better-than-human level performance at computer vision tasks.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"---\n**[Introduction to Machine Learning Home Page](https://www.kaggle.com/learn/intro-to-machine-learning)**\n\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}