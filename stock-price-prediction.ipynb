{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"fundamentals = '../input/nyse/fundamentals.csv'\nprices_split_adjusted = '../input/nyse/prices-split-adjusted.csv'\nprices = '../input/nyse/prices.csv'\nsecurities = '../input/nyse/securities.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.arima_model import ARMA\nimport statsmodels.api as sm\nfrom statsmodels.tsa.arima_process import ArmaProcess\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fundamentals = pd.read_csv (fundamentals)\nprices_split_adjusted = pd.read_csv (prices_split_adjusted)\nprices = pd.read_csv (prices)\nsecurities = pd.read_csv (securities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fundamentals.head ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fundamentals.info ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prices_split_adjusted.head ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prices_split_adjusted.info ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prices.head ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prices.info ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"securities.head ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"securities.info ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prices_subset = prices.loc [(prices ['symbol'] == 'EBAY') | (prices ['symbol'] == 'NVDA') | (prices ['symbol'] == 'YHOO') | (prices ['symbol'] == 'AAPL'), :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prices_subset.tail ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"price_table = pd.pivot_table (data = prices_subset, index = 'date', columns = 'symbol', values = 'close' )\ndf = pd.DataFrame (price_table, columns = ['AAPL', 'EBAY', 'NVDA', 'YHOO'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.index = pd.to_datetime (df.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.index.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"round (df [['AAPL', 'EBAY', 'NVDA', 'YHOO']].describe (),2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap (df.corr (), annot = True)\nplt.show ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure (figsize = (20,7))\nax1 = plt.subplot (2,1,1)\ndf [['EBAY', 'NVDA', 'YHOO']].plot (ax = ax1)\n\nax2 = plt.subplot (2,1,2)\ndf [['AAPL']].plot (ax = ax2)\n\nplt.tight_layout ()\nplt.show ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.boxplot ()\nplt.show ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = df.iloc [(df.index >= '2016-12-01') & (df.index < '2016-12-30'), :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df.iloc [df.index < '2016-12-01', :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train [['EBAY', 'NVDA', 'YHOO']]\ny_train = train ['AAPL']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test [['EBAY', 'NVDA', 'YHOO']]\ny_test = test ['AAPL']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#base model\nfrom math import sqrt\n# Fit our model and generate predictions\nmodel = Ridge()\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)\nscore = sqrt (mean_squared_error (y_test, predictions))\nprint(round (score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.concat ([X_train, y_train], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Transforming"},{"metadata":{"trusted":true},"cell_type":"code","source":"#transforming function\ndef percent_change(series):\n    # Collect all *but* the last value of this window, then the final value\n    previous_values = series[:-1]\n    last_value = series[-1]\n\n    # Calculate the % difference between the last value and the mean of earlier values\n    percent_change = (last_value - np.mean(previous_values)) / np.mean(previous_values)\n    return percent_change\n\ndf_perc = df1.rolling(50).apply (percent_change).dropna ()\ndf_perc.loc[\"2014\":\"2015\"].plot(figsize = (20,5))\nplt.xticks (rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# removing outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_outliers(series):\n    # Calculate the absolute difference of each timepoint from the series mean\n    absolute_differences_from_mean = np.abs(series - np.mean(series))\n    \n    # Calculate a mask for the differences that are > 3 standard deviations from zero\n    this_mask = absolute_differences_from_mean > (np.std (series) * 3)\n    \n    # Replace these values with the median accross the data\n    series[this_mask] = np.nanmedian (series)\n    return series\n\n# Apply your preprocessing function to the timeseries and plot the results\ndf_perc = df_perc.apply (replace_outliers)\ndf_perc.loc[\"2014\":\"2015\"].plot(figsize = (20,5))\nplt.xticks (rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# generating other features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define a rolling window with Pandas, excluding the right-most datapoint of the window\ndf_perc_rolling = df_perc.rolling(50, min_periods=5, closed = 'right')\n\n# Define the features you'll calculate for each window\nfeatures_to_calculate = [np.min, np.max, np.mean, np.std]\n\n# Calculate these features for your rolling window object\nfeatures = df_perc_rolling.aggregate(features_to_calculate)\n\n# Plot the results\n\nax = features.loc[:\"2011-01\"].plot(figsize = (15,10))\n\ndf_perc ['EBAY'].loc[:\"2011-01\"].plot(ax=ax, color='k', alpha=.1, lw=0.1, figsize = (15,10))\nax.legend(loc=(1.01, .6))\nplt.xticks (rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = features.apply (lambda x : x.fillna (np.nanmedian (x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features.columns = ['AAPL_min', 'AAPL_max', 'AAPL_mean', 'AAPL_std', 'EBAY_min', 'EBAY_max', 'EBAY_mean', 'EBAY_std','NVDA_min', 'NVDA_max', 'NVDA_mean', 'NVDA_std', 'YHOO_min', 'YHOO_max', 'YHOO_mean', 'YHOO_std' ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# percentile features\nfrom functools import partial\npercentiles = [1, 10, 25, 50, 75, 90, 99]\n\n# Use a list comprehension to create a partial function for each quantile\npercentile_functions = [partial (np.percentile, q=percentile) for percentile in percentiles]\n\n# Calculate each of these quantiles on the data using a rolling window\ndf_perc_rolling = df_perc.rolling(50, min_periods=5, closed = 'right')\nfeatures_percentiles = df_perc_rolling.agg (percentile_functions).apply (lambda x : x.fillna (np.nanmedian (x)))\n\nax = features_percentiles.loc[:'2011-01-01', 'EBAY'].plot(cmap=plt.cm.viridis, figsize = (15,10))\nax.legend(percentiles, loc=(1.01, .5))\nplt.xticks (rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_percentiles.columns = ['AAPL_perc_1','AAPL_perc_10','AAPL_perc_25','AAPL_perc_50','AAPL_perc_75','AAPL_perc_90','AAPL_perc_99', 'EBAY_perc_1','EBAY_perc_10','EBAY_perc_25','EBAY_perc_50','EBAY_perc_75','EBAY_perc_90','EBAY_perc_99', 'NVDA_perc_1','NVDA_perc_10','NVDA_perc_25','NVDA_perc_50','NVDA_perc_75','NVDA_perc_90','NVDA_perc_99', 'YHOO_perc_1','YHOO_perc_10','YHOO_perc_25','YHOO_perc_50','YHOO_perc_75','YHOO_perc_90','YHOO_perc_99']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# These are the \"time lags\"\nshifts = np.arange(1, 11).astype(int)\n\ndf_shifted = pd.DataFrame (index = df_perc.index, columns = None)\ndf_shifted.fillna (0, inplace = True)\n\nfor x,ax in zip (['EBAY', 'NVDA', 'YHOO'], ['ax0', 'ax1', 'ax2']):\n    \n    # Use a dictionary comprehension to create name: value pairs, one pair per shift\n    shifted_data = {\"lag_{}_day_{}\".format(day_shift,x): df_perc [x].shift(day_shift) for day_shift in shifts}\n    \n    # Convert into a DataFrame for subsequent use\n    shifted = pd.DataFrame (shifted_data)\n    \n                   \n    df_shifted = pd.concat ([df_shifted, shifted], axis = 1)\n    df_shifted = df_shifted.apply (lambda x : x.fillna (np.nanmedian (x)))\n    # Plot the first 100 samples of each\n    ax = shifted.iloc[:100].plot(cmap=plt.cm.viridis, figsize = (20,5))\n    df_perc [x].iloc[:100].plot(color='r', lw=2, figsize = (20,5))\n    ax.legend(loc='best')\n    plt.xticks (rotation = 90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tot = pd.concat ([df1,features,features_percentiles, df_shifted ], axis = 1).dropna ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# date features\nX_tot['day_of_week'] = X_tot.index.dayofweek\nX_tot['week_of_year'] = X_tot.index.weekofyear\nX_tot['month_of_year'] = X_tot.index.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# date features\nX_test['day_of_week'] = X_test.index.dayofweek\nX_test['week_of_year'] = X_test.index.weekofyear\nX_test['month_of_year'] = X_test.index.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tot.head ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = X_tot ['AAPL']\nX_tot = X_tot.drop ('AAPL', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_test.merge (X_tot.drop (['EBAY', 'NVDA', 'YHOO'], axis = 1), on = ['day_of_week', 'week_of_year', 'month_of_year'], how = 'left').drop_duplicates (subset = ['day_of_week', 'week_of_year', 'month_of_year'], keep = 'last')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tot.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model\nfrom sklearn.metrics import mean_squared_error\n# Fit our model and generate predictions\nmodel = Ridge(11000)\nmodel.fit(X_tot, Y)\npredictions = model.predict(X_test)\nscore = sqrt (mean_squared_error (y_test, predictions))\nprint(round (score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#feature importance\nplt.figure (figsize = (20,4))\ncoefs = pd.Series (dict (zip (list (X_tot.columns), list(abs (model.coef_)))))\nabs (coefs).sort_values (ascending = False).plot.bar ()\nplt.show ()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter (x = y_test, y = predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Accuracy = round (np.corrcoef (y_test, predictions)[0,1]*100)\n\nprint ('The apple stock price for Dec, 2016 has been predicted with accuracy of {}'.format (Accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}